{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"divine_transformer.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOLnxuIT3pa5pwLz0VlNydO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IktUvj6AndiG","executionInfo":{"status":"ok","timestamp":1619943172050,"user_tz":-120,"elapsed":733,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["import io\n","import pickle\n","import time\n","import numpy as np\n","import random\n","import sys\n","import time\n","import copy\n","import re\n","import tensorflow as tf"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0rrwCS0oWgC","executionInfo":{"status":"ok","timestamp":1619942613863,"user_tz":-120,"elapsed":5082,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"3793592b-a949-4025-c9e5-f8b148972463"},"source":["!pip install levenshtein\n","from Levenshtein import distance as levenshtein_distance"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting levenshtein\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/41/ff25ae28c972a63abde29cd5cea7c648ae0e16b334693cede0522e66dd68/levenshtein-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (158kB)\n","\r\u001b[K     |██                              | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from levenshtein) (56.0.0)\n","Installing collected packages: levenshtein\n","Successfully installed levenshtein-0.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNtKlcYAqGYw","executionInfo":{"status":"ok","timestamp":1619942646193,"user_tz":-120,"elapsed":36852,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"c756bf95-d3d4-404e-e43a-caba06ee9c0f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/transformer/' "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lwsdLDJMn0ar"},"source":["## ATTENTION"]},{"cell_type":"code","metadata":{"id":"_qm-mmfSnv-y","executionInfo":{"status":"ok","timestamp":1619942649226,"user_tz":-120,"elapsed":716,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","    return output, attention_weights\n","\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        assert d_model % self.num_heads == 0\n","        self.depth = d_model // self.num_heads\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention,\n","                                        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","        concat_attention = tf.reshape(scaled_attention,\n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        return output, attention_weights\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0OFoYvHn5Ei"},"source":["## EVALUATE"]},{"cell_type":"code","metadata":{"id":"TJwuxgfVohBG","executionInfo":{"status":"ok","timestamp":1619943008297,"user_tz":-120,"elapsed":3143,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def sampling(k, predictions, prev_pred, space, syl, start):\n","    def generation(temp):\n","        top_k_id, top_k_prob = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n","                               (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n","        top_k_prob = top_k_prob ** temp\n","        prob_sum = sum(top_k_prob)\n","        r = random.random() * prob_sum\n","        j = 0\n","        while True:\n","            if r - top_k_prob[j] <= 0:\n","                return tf.cast(tf.convert_to_tensor([[top_k_id[j]]]), tf.int64)\n","            r -= top_k_prob[j]\n","            j += 1\n","\n","    if len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl:\n","        prediction_id = generation(3)\n","    elif len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl:\n","        prediction_id = generation(-3)\n","    else:\n","        prediction_id = tf.argmax(predictions, axis=-1)\n","    return prediction_id\n","\n","\n","def evaluate(sentence, two_way_X, two_way_y, max_length=1000):\n","    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence)]), tf.int64)\n","\n","    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n","    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n","    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n","    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n","    output = tf.convert_to_tensor([t_init])\n","    output = tf.expand_dims(output, 0)\n","    output = tf.cast(output, tf.int64)\n","\n","    prev_pred = [t_init]\n","\n","    for i in range(max_length):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","        # predictions.shape == (batch_size, seq_len, vocab_size)\n","        predictions, attention_weights = transformer(encoder_input,\n","                                                     output,\n","                                                     False,\n","                                                     enc_padding_mask,\n","                                                     combined_mask,\n","                                                     dec_padding_mask)\n","        # select the last word from the seq_len dimension\n","        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","\n","        predicted_id = sampling(10, predictions, prev_pred, space, syl, start)\n","\n","        prev_pred.append(predicted_id)\n","        output = tf.concat([output, predicted_id], axis=-1)\n","        # return the result if the predicted_id is equal to the end token\n","        if predicted_id == t_end:\n","            break\n","    # output.shape (1, tokens)\n","    text = detokenize(two_way_y, output)\n","    return text, attention_weights\n","\n","\n","def evaluate_test(X_test, y_test, two_way_X, two_way_y):\n","    print(len(X_test))\n","    distances = []\n","    for query_sent, true_sent in zip(X_test[30:50], y_test[30:50]):\n","        pred_text, attention_w = evaluate(query_sent, two_way_X, two_way_y)\n","        pred_text = make_human_understandable(pred_text)\n","        true_sent = make_human_understandable(true_sent)\n","        print(f\"pred: {pred_text}\\norig: {true_sent}\")\n","        lev = levenshtein_distance(pred_text, true_sent)\n","        lower = abs(len(pred_text) - len(true_sent))\n","        upper = max(len(pred_text), len(true_sent))\n","        distances.append((lev - lower) / (upper - lower))\n","    print(1 - np.mean(distances))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfdLb_Y0HkIs"},"source":["# BEAM SEARFCH"]},{"cell_type":"code","metadata":{"id":"HB-Uhb6XHjUU","executionInfo":{"status":"ok","timestamp":1619943177524,"user_tz":-120,"elapsed":754,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["\n","N_BEAM = 2\n","K = 10\n","TEMP = 1\n","\n","\n","def sampling_flows(flows_array):\n","    all_flows = copy.deepcopy(flows_array)\n","    drawn_flows = []\n","    for _ in range(N_BEAM):\n","        top_k_prob = [f.prob for f in all_flows]\n","        top_k_prob = np.array([e if e > 0 else 0.05 for e in top_k_prob])\n","        top_k_prob = top_k_prob ** TEMP\n","        prob_sum = sum(top_k_prob)\n","        r = random.random() * prob_sum\n","        j = 0\n","        while True:\n","            if r - top_k_prob[j] <= 0:\n","                drawn_flows.append(all_flows[j])\n","                all_flows.pop(j)\n","                break\n","            r -= top_k_prob[j]\n","            j += 1\n","    return drawn_flows\n","\n","\n","def next_predictions(encoder_input, output, k, argmax):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n","    predictions, attention_weights = transformer(encoder_input,\n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","    if not argmax:\n","        top_k_id_, top_k_prob_ = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n","                                 (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n","        return top_k_id_, top_k_prob_\n","    else:\n","        return tf.argmax(predictions, axis=-1)\n","\n","\n","class Flow:\n","    def __init__(self, init, prob):\n","        self.output = init\n","        self.prob = prob\n","\n","\n","def beam_search(sentence, two_way_X, two_way_y, max_length=1000):\n","    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence, X=True)]), tf.int64)\n","    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n","    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n","    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n","    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n","    output = tf.convert_to_tensor([t_init])\n","    output = tf.expand_dims(output, 0)\n","    output = tf.cast(output, tf.int64)\n","\n","    flows_array = [Flow(output, 1)]\n","    best_flows = []\n","    for u in range(max_length):\n","        if False and u % 11 == 0:\n","            print(\"Generazione sillaba: \" + str(u))\n","        new_flow_array = []\n","        for e in flows_array:\n","            prev_pred = e.output.numpy().flatten()\n","            if (len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl) or \\\n","                    (len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl):\n","                top_k_id, top_k_prob = next_predictions(encoder_input, e.output, k=K, argmax=False)\n","                for i in range(len(top_k_id)):\n","                    new_out = tf.concat(\n","                        [(copy.deepcopy(e)).output, tf.cast(tf.convert_to_tensor([[top_k_id[i]]]), tf.int64)], axis=-1)\n","                    new_flow_array.append(Flow(new_out, top_k_prob[i] * e.prob))\n","            else:\n","                new_out = tf.concat(\n","                    [(copy.deepcopy(e)).output, next_predictions(encoder_input, e.output, k=K, argmax=True)], axis=-1)\n","                new_flow_array.append(Flow(new_out, e.prob))\n","\n","        flows_array = new_flow_array\n","        # flows_array = sorted(flows_array, key=lambda f: f.prob, reverse=True)[:N_BEAM]\n","        if len(flows_array) > N_BEAM:\n","            flows_array = sampling_flows(flows_array)\n","\n","        to_pop = []\n","        for j, flow in enumerate(flows_array):\n","            if flow.output.numpy().flatten()[-1] == t_end:\n","                best_flows.append(flow)\n","                to_pop.append(flow)\n","        [flows_array.remove(p) for p in to_pop]\n","        if len(best_flows) == N_BEAM:\n","            result = (max(best_flows, key=lambda f: f.prob)).output\n","            text = detokenize(two_way_y, result)\n","            return text\n"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkJy3R0DrjLz"},"source":["# ENCODER DECODER"]},{"cell_type":"code","metadata":{"id":"rw8o-6mbrdAu","executionInfo":{"status":"ok","timestamp":1619942653810,"user_tz":-120,"elapsed":733,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","        return out2\n","\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        # enc_output.shape == (batch_size, input_seq_len, d_model)\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","        attn2, attn_weights_block2 = self.mha2(\n","            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","        return out3, attn_weights_block1, attn_weights_block2\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                 maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                self.d_model)\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n","                           for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","        # adding embedding and position encoding.\n","        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","        return x  # (batch_size, input_seq_len, d_model)\n","\n","\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","                 maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n","                           for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                                   look_ahead_mask, padding_mask)\n","            attention_weights[f'decoder_layer{i + 1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i + 1}_block2'] = block2\n","        # x.shape == (batch_size, target_seq_len, d_model)\n","        return x, attention_weights\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmSemJjjpNfH"},"source":["# TRANSFORMER TOOLS"]},{"cell_type":"code","metadata":{"id":"QCMw34fepNHC","executionInfo":{"status":"ok","timestamp":1619942656630,"user_tz":-120,"elapsed":740,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis, :],\n","                            d_model)\n","\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='gelu'),  # (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # add extra dimensions to add the padding\n","    # to the attention logits.\n","    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n","\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask  # (seq_len, seq_len)\n","\n","\n","def create_masks(inp, tar):\n","    # Encoder padding mask\n","    enc_padding_mask = create_padding_mask(inp)\n","    # Used in the 2nd attention block in the decoder.\n","    # This padding mask is used to mask the encoder outputs.\n","    dec_padding_mask = create_padding_mask(inp)\n","    # Used in the 1st attention block in the decoder.\n","    # It is used to pad and mask future tokens in the input received by\n","    # the decoder.\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, combined_mask, dec_padding_mask\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xuNecFH6o1nU"},"source":["# TRANSFORMER CLASS"]},{"cell_type":"code","metadata":{"id":"7UwyGFL0otlj","executionInfo":{"status":"ok","timestamp":1619942659374,"user_tz":-120,"elapsed":847,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                 target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","        self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n","                                 input_vocab_size, pe_input, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n","                               target_vocab_size, pe_target, rate)\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","        dec_output, attention_weights = self.decoder(\n","            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","        return final_output, attention_weights"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uk3GO3wh8e16"},"source":["# ENCODE TOKENIZE \\& PERSONAL TOOLS"]},{"cell_type":"code","metadata":{"id":"VZGkOv_U8diI","executionInfo":{"status":"ok","timestamp":1619942673268,"user_tz":-120,"elapsed":789,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def encode_dataset(X, y):\n","    \"\"\"\n","        Creates integer encoded version of the dataset.\n","    \"\"\"\n","    encoded_X = TwoWay()\n","    encoded_set = []\n","    for row in X:\n","        tmp_row = re.sub(r'<start>|<end>|<syl>', r'', row)\n","        [[encoded_set.append(c) for c in w] for w in tmp_row.split('<s>')]\n","    encoded_set += ['<start>', '<end>', '<s>', '<t_init>', '<t_end>']\n","    encoded_set = set(encoded_set)\n","    [encoded_X.add(i + 1, w) for i, w in enumerate(encoded_set)]\n","    with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'wb') as handle:\n","        pickle.dump(encoded_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    encoded_y = TwoWay()\n","    encoded_set = []\n","    for row in y:\n","        tmp_row = re.sub(r'<syl>', r'<s>', row)\n","        tmp_row = re.sub(r'<start>|<end>|<c>', r'', tmp_row)\n","        [encoded_set.append(w) for w in tmp_row.split('<s>')]\n","    encoded_set += ['<syl>', '<s>', '<start>', '<end>', '<t_init>', '<t_end>', '<c>']\n","    encoded_set = set(encoded_set)\n","    encoded_set.remove(\"\")\n","    [encoded_y.add(i + 1, w) for i, w in enumerate(encoded_set)]\n","    with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'wb') as handle:\n","        pickle.dump(encoded_y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    print(\"Data saved successfully!\")\n","\n","\n","def tokenize(two_way, line, X):\n","    spaced_line = re.sub(r'<', r' <', line)\n","    spaced_line = re.sub(r'>', r'> ', spaced_line)\n","    spaced_line = re.sub(r'^ | $', r'', spaced_line)\n","    spaced_line = re.sub(r'[ ]+', r' ', spaced_line)\n","    spaced_line = spaced_line.split(' ')\n","    while True:\n","        try:\n","            spaced_line.remove('')\n","        except ValueError:\n","            break\n","\n","    if X: \n","        tok_X = []\n","        for w in spaced_line:\n","            if w in ['<start>', '<end>', '<s>', '<t_init>', '<t_end>', '<c>']:\n","                tok_X.append(two_way.get(w))\n","            else:\n","                [tok_X.append(two_way.get(c)) for c in w]\n","        return tok_X\n","    else:\n","        return [two_way.get(e) for e in spaced_line]\n","\n","\n","def detokenize(two_way, line):\n","    sentence = [two_way.get(e.numpy()) for e in line[0]]\n","    return ''.join(sentence)\n","\n","\n","def detokenize_(two_way, line):\n","    sentence = [two_way.get(e) for e in line]\n","    return ''.join(sentence)\n","\n","\n","def make_human_understandable(sentence, keep_syl=True):\n","    sentence = re.sub(r'<start>|<t_init>|<t_end>|<end>', r'', sentence)\n","    if keep_syl:\n","        sentence = re.sub(r'<syl>', r'|', sentence)\n","    else:\n","        sentence = re.sub(r'<syl>', r'', sentence)\n","    sentence = re.sub(r'<s>', r' ', sentence)\n","    return sentence\n","\n","\n","def tokenize_pairs(X, y):\n","    sliding_window = 6\n","    X_tok = []\n","    y_tok = []\n","    for i in range(len(X)):\n","        next_to_check = ''\n","        for s in X[i:i + sliding_window + 3]:\n","            next_to_check += s\n","        if not re.search(r'<canto>', next_to_check):\n","            terz = [tokenize(two_way_X, '<t_init>', X=True)[0]]\n","            terz_y = [tokenize(two_way_y, '<t_init>', X=False)[0]]\n","            for k in range(sliding_window):\n","                if (k % 3 == 0) and (k > 0):\n","                    terz += tokenize(two_way_X, '<t_end>', X=True)\n","                    terz += tokenize(two_way_X, '<t_init>',X=True)\n","                terz += (tokenize(two_way_X, X[i + k], X=True))\n","\n","            terz += tokenize(two_way_X, '<t_end>', X=True)\n","            for j in range(3):\n","                terz_y += (tokenize(two_way_y, y[i + j + sliding_window], X=False))\n","            terz_y += tokenize(two_way_y, '<t_end>', X=False)\n","            X_tok.append(terz)\n","            y_tok.append(terz_y)\n","\n","    return X_tok, y_tok\n","\n","\n","def make_batches(X_y_tok, batch_size):\n","    batches = []\n","    X_tok, y_tok = X_y_tok\n","    for i in range(0, len(X_tok), batch_size):\n","        if (batch_size + i) < len(X_tok):\n","            batches.append((tf.cast(tf.ragged.constant(X_tok[i:i + batch_size]), tf.int64).to_tensor(),\n","                            (tf.cast(tf.ragged.constant(y_tok[i:i + batch_size]), tf.int64).to_tensor())))\n","        else:\n","            break\n","        # TODO: use the whole dataset\n","    return batches"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QUWxR546pUSP"},"source":["# TRANSFORMER TRAINING"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wsly3FnGuAcW","executionInfo":{"status":"ok","timestamp":1619942681461,"user_tz":-120,"elapsed":802,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"e9f3cd48-9a52-46f0-fc23-efb209ac12ef"},"source":["!ls gdrive/MyDrive/transformer/"],"execution_count":10,"outputs":[{"output_type":"stream","text":["checkpoints  resources\ttraining_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzS2YHQtpAqa","executionInfo":{"status":"ok","timestamp":1619942695501,"user_tz":-120,"elapsed":9995,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"aee998c1-4847-42c9-fbeb-9011591a7816"},"source":["class TwoWay:\n","    def __init__(self):\n","        self.d = {}\n","\n","    def add(self, k, v):\n","        self.d[k] = v\n","        self.d[v] = k\n","\n","    def remove(self, k):\n","        self.d.pop(self.d.pop(k))\n","\n","    def get(self, k):\n","        return self.d[k]\n","\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","\n","\n","# INITIALIZERS\n","\n","X = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","y = np.loadtxt(\"gdrive/MyDrive/transformer/resources/y.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","X_val = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","y_val = np.loadtxt(\"gdrive/MyDrive/transformer/resources/y_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","X_test = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X_test.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","\n","# !!!!!!!!!!!!!!!\n","# encode_dataset(np.hstack((X, X_val)), np.hstack((y, y_val)))\n","\n","with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'rb') as f:\n","    two_way_X = pickle.load(f)\n","with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'rb') as f:\n","    two_way_y = pickle.load(f)\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","val_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","'''\n","ORIGINALS\n","\n","num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.1\n","'''\n","\n","EPOCHS = 200\n","num_layers = 4\n","d_model = 256\n","dff = 1024\n","num_heads = 8\n","dropout_rate = 0.1\n","\n","learning_rate = CustomSchedule(d_model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n","val_loss = tf.keras.metrics.Mean(name='val_accuracy')\n","\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=len(two_way_X.d),\n","    target_vocab_size=len(two_way_y.d),\n","    pe_input=500,\n","    pe_target=500,\n","    rate=dropout_rate)\n","\n","checkpoint_path = \"gdrive/MyDrive/transformer/checkpoints/train\"\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print('Latest checkpoint restored!!')\n","\n","\n","def get_encoder_emb(two_way_X):\n","    weights = transformer.tokenizer.embedding.get_weights()[0]\n","    vocab = two_way_X\n","\n","    out_v = io.open('gdrive/MyDrive/transformer/training_data/vectors_enc.tsv', 'w', encoding='utf-8')\n","    out_m = io.open('gdrive/MyDrive/transformer/training_data/metadata_enc.tsv', 'w', encoding='utf-8')\n","    for index in range(len(vocab.d) // 2):\n","        if index == 0:\n","            continue  # skip 0, it's padding.\n","        vec = weights[index]\n","        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","        out_m.write(vocab.get(index) + \"\\n\")\n","    out_v.close()\n","    out_m.close()\n","\n","def get_decoder_emb(two_way_y):\n","    weights = transformer.decoder.embedding.get_weights()[0]\n","    vocab = two_way_y\n","\n","    out_v = io.open('gdrive/MyDrive/transformer/training_data/vectors_dec.tsv', 'w', encoding='utf-8')\n","    out_m = io.open('gdrive/MyDrive/transformer/training_data/metadata_dec.tsv', 'w', encoding='utf-8')\n","    for index in range(len(vocab.d) // 2):\n","        if index == 0:\n","            continue  # skip 0, it's padding.\n","        vec = weights[index]\n","        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","        out_m.write(vocab.get(index) + \"\\n\")\n","    out_v.close()\n","    out_m.close()\n","\n","def accuracy_function(real, pred):\n","    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n","\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n","\n","\n","def fit(train_batches, val_batches):\n","    train_accuracies = []\n","    val_accuracies = []\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(EPOCHS):\n","        start = time.time()\n","        train_loss.reset_states()\n","        train_accuracy.reset_states()\n","        val_loss.reset_states()\n","        val_accuracy.reset_states()\n","\n","        for (batch, (inp, tar)) in enumerate(train_batches):\n","            train_step(inp, tar)\n","            inp_val, tar_val = val_batches[batch % len(val_batches)]\n","            validation_step(inp_val, tar_val)\n","\n","            if batch % 100 == 0:\n","                print(\n","                    f'Epoch {epoch + 1} Batch {batch}'\n","                    f' - Loss {train_loss.result():.4f}'\n","                    f' - Accuracy {train_accuracy.result():.4f}'\n","                    f' - Val Loss {val_loss.result():.4f}'\n","                    f' - Val Accuracy {val_accuracy.result():.4f}'\n","                )\n","\n","                train_accuracies.append(train_accuracy.result())\n","                val_accuracies.append(val_accuracy.result())\n","                train_losses.append(train_loss.result())\n","                val_losses.append(val_loss.result())\n","\n","                if (epoch + 1) % 8 == 0:\n","                    ckpt_save_path = ckpt_manager.save()\n","                    print(f'Saving checkpoint for epoch {epoch + 1} at {ckpt_save_path}')\n","                    np.save('gdrive/MyDrive/transformer/training_data/train_accuracies.npy', train_accuracies)\n","                    np.save('gdrive/MyDrive/transformer/training_data/val_accuracies.npy', val_accuracies)\n","                    np.save('gdrive/MyDrive/transformer/training_data/train_losses.npy', train_losses)\n","                    np.save('gdrive/MyDrive/transformer/training_data/val_losses.npy', val_losses)\n","\n","                    get_encoder_emb(two_way_X)\n","                    get_decoder_emb(two_way_y)\n","\n","        print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n","        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n","\n","    return np.array(train_accuracies), np.array(train_losses), np.array(val_accuracies), np.array(val_losses)\n","\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(inp, tar_inp,\n","                                     True,\n","                                     enc_padding_mask,\n","                                     combined_mask,\n","                                     dec_padding_mask)\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","    train_loss(loss)\n","    train_accuracy(accuracy_function(tar_real, predictions))\n","\n","\n","@tf.function(input_signature=val_step_signature)\n","def validation_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","    predictions, _ = transformer(inp, tar_inp,\n","                                 False,\n","                                 enc_padding_mask,\n","                                 combined_mask,\n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","    val_loss(loss)\n","    val_accuracy(accuracy_function(tar_real, predictions))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Latest checkpoint restored!!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s5uYNRK2sbmW"},"source":["# MAIN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":844},"id":"6ynLiX5NrNI9","executionInfo":{"status":"error","timestamp":1619943999659,"user_tz":-120,"elapsed":283654,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"7f774803-068d-4149-e068-fa346b7efd93"},"source":["print((detokenize_(two_way_X, tokenize_pairs(X, y)[0][0])))\n","print((detokenize_(two_way_y, tokenize_pairs(X, y)[1][0])))\n","\n","BATCH_SIZE = 64\n","\n","train_batches = make_batches(tokenize_pairs(X, y), batch_size=BATCH_SIZE)\n","val_batches = make_batches(tokenize_pairs(X_val, y_val), batch_size=BATCH_SIZE)\n","\n","\n","'''\n","# Saves pkl with new words not in X\n","with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'wb') as handle:\n","    pickle.dump(two_way_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'wb') as handle:\n","    pickle.dump(two_way_y, handle, protocol=pickle.HIGHEST_PROTOCOL)'''\n","\n","\n","# train_accuracies, train_losses, val_accuracies, val_losses = fit(train_batches, val_batches)\n","\n","def generator(length):\n","    array_input = list(X_test[0:6])\n","    last_input_array = []\n","    for i in range(length):\n","        if last_input_array:\n","            [array_input.pop(0) for _ in range(3)]\n","            for e in last_input_array:\n","                array_input.append(re.sub(r'<syl>', '', e))\n","        # from array to text\n","        text_input = '<t_init>'\n","        for k, s in enumerate(array_input):\n","            if (k % 3 == 0) and (k > 0):\n","                text_input += '<t_end>'\n","                text_input += '<t_init>'\n","            text_input += s\n","        text_input += '<t_end>'\n","        # end textification\n","        # last_input, _ = evaluate.evaluate(text_input, two_way_X, two_way_y, max_length=5000)\n","        text_input = re.sub(r'<c>', r'', text_input)\n","        last_input = beam_search(text_input, two_way_X, two_way_y, max_length=5000)\n","\n","        ###\n","        last_input = re.sub(r'<t_init>|<t_end>', r'', last_input)\n","        last_input = re.sub(r'<end>', r'<end>+', last_input)\n","        last_input_array = last_input.split('+')\n","        for l in last_input_array:\n","            print(make_human_understandable(l, True))\n","        print()\n","\n","\n","generator(10)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["<t_init><start>nel<s>mezzo<s>del<s>cammin<s>di<s>nostra<s>vita<s><end><start>mi<s>ritrovai<s>per<s>una<s>selva<s>oscura<s><end><start>ché<s>la<s>diritta<s>via<s>era<s>smarrita<s><end><t_end><t_init><start>ahi<s>quanto<s>a<s>dir<s>qual<s>era<s>è<s>cosa<s>dura<s><end><start>esta<s>selva<s>selvaggia<s>e<s>aspra<s>e<s>forte<s><end><start>che<s>nel<s>pensier<s>rinova<s>la<s>paura<s><end><t_end>\n","<t_init><start><syl>tan<syl>t'<s>è<s><syl>a<syl>ma<syl>ra<s><syl>che<c><s><syl>po<syl>co<s>è<s><syl>più<s><syl>mor<syl>te<s><end><start><syl>ma<s><syl>per<s><syl>trat<syl>tar<c><s><syl>del<s><syl>ben<s><syl>ch'<s>i'<s><syl>vi<s><syl>tro<syl>vai<s><end><start><syl>di<syl>rò<s><syl>de<s><syl>l'<s>al<syl>tre<c><s><syl>co<syl>se<s><syl>ch'<s>i'<s><syl>v'<s>ho<s><syl>scor<syl>te<s><end><t_end>\n","|che |po|ran |per<c> |ri|tor|re |di |d' un |con|tro \n","|ve|der |la |vo|ce |de<c> |lo |spe|glio |ne|sto \n","|che |si |no|ta|ro |non<c> |al|tri|no |quan|to \n","\n","\n","|a |que|sta |ve|ra<c> |con|co|min|cia |tras|se \n","|poi |si |tor|nò<c> |sé |dur |con |la |sua |bar|ca \n","|e |ne |la |don|na |de<c> |la |sua |mi|li|zia \n","\n","\n","|di |ra|gio|na|re an|cor<c> |men |te|mi|ri|ni \n","|si |mo|vea |pri|ma |per<c> |soz|za |mi |ma|le \n","|di |tan|ta |se|ra |giù<c> |dal |mio |ve|der |quan|to \n","\n","\n","|di |quel|la |fie|ra<c> |sel|va |ter|mi|na|va \n","|da |in|di |dio<c> |si |fe|ro a |quel |sa|po|re \n","|che |tu |non |ben<c> |si |ti|sti |per |l' a|cer|na \n","\n","\n","|e |io |la |mia<c> |me|mo|ria |che |la |ro|ta \n","|e |poi |lo |vo|stro |e<c> |tan|to |fe|ro|ce \n","|le |lo|co |che<c> |là |giù |si |di|mo|stra|ro \n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-c389535770b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-c389535770b2>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(length)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# last_input, _ = evaluate.evaluate(text_input, two_way_X, two_way_y, max_length=5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<c>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlast_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_way_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_way_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-88337259ded9>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(sentence, two_way_X, two_way_y, max_length)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 new_out = tf.concat(\n\u001b[0;32m---> 75\u001b[0;31m                     [(copy.deepcopy(e)).output, next_predictions(encoder_input, e.output, k=K, argmax=True)], axis=-1)\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mnew_flow_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-88337259ded9>\u001b[0m in \u001b[0;36mnext_predictions\u001b[0;34m(encoder_input, output, k, argmax)\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                  \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                  \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                                  dec_padding_mask)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (batch_size, 1, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-8d11101eccc8>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         dec_output, attention_weights = self.decoder(\n\u001b[0;32m---> 15\u001b[0;31m             tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, tar_seq_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-b6edb0f8d35b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n\u001b[0;32m---> 95\u001b[0;31m                                                    look_ahead_mask, padding_mask)\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'decoder_layer{i + 1}_block1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'decoder_layer{i + 1}_block2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-b6edb0f8d35b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         attn2, attn_weights_block2 = self.mha2(\n\u001b[0;32m---> 40\u001b[0;31m             enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mattn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-158a9717dab5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, num_heads, seq_len_q, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, num_heads, seq_len_k, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;31m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    952\u001b[0m                                                 input_list)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_in_functional_construction_mode\u001b[0;34m(layer, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m   \u001b[0;34m\"\"\"Check the arguments to see if we are constructing a functional model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3280\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tensors_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0;31m# We are constructing a functional model if any of the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0;31m# are KerasTensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":610},"id":"sx1SxSpCynEj","executionInfo":{"status":"ok","timestamp":1619944233539,"user_tz":-120,"elapsed":1578,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"1051d2fc-1f1e-46c3-caab-59f45f0fdfb3"},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_attention_head(in_tokens, translated_tokens, attention):\n","    translated_tokens = translated_tokens[1:]\n","    ax = plt.gca()\n","    ax.matshow(attention)\n","    ax.set_xticks(range(len(in_tokens)))\n","    ax.set_yticks(range(len(translated_tokens)))\n","    labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n","    ax.set_xticklabels(labels, rotation=90)\n","    labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n","    ax.set_yticklabels(labels)\n","\n","\n","def print_acc_loss():\n","    train_accuracies = np.load('gdrive/MyDrive/transformer/training_data/train_accuracies.npy')\n","    val_accuracies = np.load('gdrive/MyDrive/transformer/training_data/val_accuracies.npy')\n","    train_losses = np.load('gdrive/MyDrive/transformer/training_data/train_losses.npy')\n","    val_losses = np.load('gdrive/MyDrive/transformer/training_data/val_losses.npy')\n","\n","    plt.title(\"Accuracies\")\n","    plt.plot(range(0, 25 * len(train_accuracies), 25), train_accuracies)\n","    plt.plot(range(0, 25 * len(train_accuracies), 25), val_accuracies)\n","    plt.xlabel(\"Num batch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend([\"train_acc\", \"val_acc\"])\n","    plt.tight_layout()\n","    plt.savefig('gdrive/MyDrive/transformer/training_data/Acc_6x_3y_200ep_chars.png')\n","    plt.show()\n","    print()\n","\n","    plt.title(\"Loss\")\n","    plt.plot(range(0, 25 * len(train_accuracies), 25), train_losses)\n","    plt.plot(range(0, 25 * len(train_accuracies), 25), val_losses)\n","    plt.xlabel(\"Num batch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend([\"train_loss\", \"val_loss\"])\n","    plt.tight_layout()\n","    plt.savefig('gdrive/MyDrive/transformer/training_data/Loss_6x_3y_200ep_chars.png')\n","    plt.show()\n","\n","\n","print_acc_loss()\n","sys"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["<module 'sys' (built-in)>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"Qw9QPQNwji9N"},"source":["italicized text"]},{"cell_type":"code","metadata":{"id":"VIpUoe9mjhis"},"source":[""],"execution_count":null,"outputs":[]}]}