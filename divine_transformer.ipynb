{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "divine_transformer.ipynb",
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOLnxuIT3pa5pwLz0VlNydO"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "IktUvj6AndiG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619943172050,
     "user_tz": -120,
     "elapsed": 733,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "import io\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import tensorflow as tf"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNtKlcYAqGYw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942646193,
     "user_tz": -120,
     "elapsed": 36852,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    },
    "outputId": "c756bf95-d3d4-404e-e43a-caba06ee9c0f"
   },
   "source": [
    "'''\n",
    "# UNCOMMENT IF YOU ARE ON COLAB\n",
    "\n",
    "!pip install levenshtein\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "root_path = 'gdrive/My Drive/transformer/'\n",
    "\n",
    "# REMEMBER TO SET THE ROOT PATH WITH A REGEX IN ALL THE NOTEBOOK\n",
    "# gdrive/MyDrive/transformer/\n",
    "'''\n",
    "from Levenshtein import distance as levenshtein_distance"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwsdLDJMn0ar"
   },
   "source": [
    "## ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_qm-mmfSnv-y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942649226,
     "user_tz": -120,
     "elapsed": 716,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention,\n",
    "                                        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        return output, attention_weights\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0OFoYvHn5Ei"
   },
   "source": [
    "## EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJwuxgfVohBG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619943008297,
     "user_tz": -120,
     "elapsed": 3143,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "def sampling(k, predictions, prev_pred, space, syl, start):\n",
    "    def generation(temp):\n",
    "        top_k_id, top_k_prob = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n",
    "                               (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n",
    "        top_k_prob = top_k_prob ** temp\n",
    "        prob_sum = sum(top_k_prob)\n",
    "        r = random.random() * prob_sum\n",
    "        j = 0\n",
    "        while True:\n",
    "            if r - top_k_prob[j] <= 0:\n",
    "                return tf.cast(tf.convert_to_tensor([[top_k_id[j]]]), tf.int64)\n",
    "            r -= top_k_prob[j]\n",
    "            j += 1\n",
    "\n",
    "    if len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl:\n",
    "        prediction_id = generation(3)\n",
    "    elif len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl:\n",
    "        prediction_id = generation(-3)\n",
    "    else:\n",
    "        prediction_id = tf.argmax(predictions, axis=-1)\n",
    "    return prediction_id\n",
    "\n",
    "\n",
    "def evaluate(sentence, two_way_X, two_way_y, max_length=1000):\n",
    "    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence)]), tf.int64)\n",
    "\n",
    "    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n",
    "    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n",
    "    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n",
    "    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n",
    "    output = tf.convert_to_tensor([t_init])\n",
    "    output = tf.expand_dims(output, 0)\n",
    "    output = tf.cast(output, tf.int64)\n",
    "\n",
    "    prev_pred = [t_init]\n",
    "\n",
    "    for i in range(max_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = sampling(10, predictions, prev_pred, space, syl, start)\n",
    "\n",
    "        prev_pred.append(predicted_id)\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == t_end:\n",
    "            break\n",
    "    # output.shape (1, tokens)\n",
    "    text = detokenize(two_way_y, output)\n",
    "    return text, attention_weights\n",
    "\n",
    "\n",
    "def evaluate_test(X_test, y_test, two_way_X, two_way_y):\n",
    "    print(len(X_test))\n",
    "    distances = []\n",
    "    for query_sent, true_sent in zip(X_test[30:50], y_test[30:50]):\n",
    "        pred_text, attention_w = evaluate(query_sent, two_way_X, two_way_y)\n",
    "        pred_text = make_human_understandable(pred_text)\n",
    "        true_sent = make_human_understandable(true_sent)\n",
    "        print(f\"pred: {pred_text}\\norig: {true_sent}\")\n",
    "        lev = levenshtein_distance(pred_text, true_sent)\n",
    "        lower = abs(len(pred_text) - len(true_sent))\n",
    "        upper = max(len(pred_text), len(true_sent))\n",
    "        distances.append((lev - lower) / (upper - lower))\n",
    "    print(1 - np.mean(distances))"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfdLb_Y0HkIs"
   },
   "source": [
    "# BEAM SEARFCH"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HB-Uhb6XHjUU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619943177524,
     "user_tz": -120,
     "elapsed": 754,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "\n",
    "N_BEAM = 2\n",
    "K = 10\n",
    "TEMP = 1\n",
    "\n",
    "\n",
    "def sampling_flows(flows_array):\n",
    "    all_flows = copy.deepcopy(flows_array)\n",
    "    drawn_flows = []\n",
    "    for _ in range(N_BEAM):\n",
    "        top_k_prob = [f.prob for f in all_flows]\n",
    "        top_k_prob = np.array([e if e > 0 else 0.05 for e in top_k_prob])\n",
    "        top_k_prob = top_k_prob ** TEMP\n",
    "        prob_sum = sum(top_k_prob)\n",
    "        r = random.random() * prob_sum\n",
    "        j = 0\n",
    "        while True:\n",
    "            if r - top_k_prob[j] <= 0:\n",
    "                drawn_flows.append(all_flows[j])\n",
    "                all_flows.pop(j)\n",
    "                break\n",
    "            r -= top_k_prob[j]\n",
    "            j += 1\n",
    "    return drawn_flows\n",
    "\n",
    "\n",
    "def next_predictions(encoder_input, output, k, argmax):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "    predictions, attention_weights = transformer(encoder_input,\n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "    if not argmax:\n",
    "        top_k_id_, top_k_prob_ = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n",
    "                                 (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n",
    "        return top_k_id_, top_k_prob_\n",
    "    else:\n",
    "        return tf.argmax(predictions, axis=-1)\n",
    "\n",
    "\n",
    "class Flow:\n",
    "    def __init__(self, init, prob):\n",
    "        self.output = init\n",
    "        self.prob = prob\n",
    "\n",
    "\n",
    "def beam_search(sentence, two_way_X, two_way_y, max_length=1000):\n",
    "    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence, X=True)]), tf.int64)\n",
    "    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n",
    "    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n",
    "    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n",
    "    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n",
    "    output = tf.convert_to_tensor([t_init])\n",
    "    output = tf.expand_dims(output, 0)\n",
    "    output = tf.cast(output, tf.int64)\n",
    "\n",
    "    flows_array = [Flow(output, 1)]\n",
    "    best_flows = []\n",
    "    for u in range(max_length):\n",
    "        if False and u % 11 == 0:\n",
    "            print(\"Generazione sillaba: \" + str(u))\n",
    "        new_flow_array = []\n",
    "        for e in flows_array:\n",
    "            prev_pred = e.output.numpy().flatten()\n",
    "            if (len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl) or \\\n",
    "                    (len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl):\n",
    "                top_k_id, top_k_prob = next_predictions(encoder_input, e.output, k=K, argmax=False)\n",
    "                for i in range(len(top_k_id)):\n",
    "                    new_out = tf.concat(\n",
    "                        [(copy.deepcopy(e)).output, tf.cast(tf.convert_to_tensor([[top_k_id[i]]]), tf.int64)], axis=-1)\n",
    "                    new_flow_array.append(Flow(new_out, top_k_prob[i] * e.prob))\n",
    "            else:\n",
    "                new_out = tf.concat(\n",
    "                    [(copy.deepcopy(e)).output, next_predictions(encoder_input, e.output, k=K, argmax=True)], axis=-1)\n",
    "                new_flow_array.append(Flow(new_out, e.prob))\n",
    "\n",
    "        flows_array = new_flow_array\n",
    "        # flows_array = sorted(flows_array, key=lambda f: f.prob, reverse=True)[:N_BEAM]\n",
    "        if len(flows_array) > N_BEAM:\n",
    "            flows_array = sampling_flows(flows_array)\n",
    "\n",
    "        to_pop = []\n",
    "        for j, flow in enumerate(flows_array):\n",
    "            if flow.output.numpy().flatten()[-1] == t_end:\n",
    "                best_flows.append(flow)\n",
    "                to_pop.append(flow)\n",
    "        [flows_array.remove(p) for p in to_pop]\n",
    "        if len(best_flows) == N_BEAM:\n",
    "            result = (max(best_flows, key=lambda f: f.prob)).output\n",
    "            text = detokenize(two_way_y, result)\n",
    "            return text\n"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkJy3R0DrjLz"
   },
   "source": [
    "# ENCODER DECODER"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rw8o-6mbrdAu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942653810,
     "user_tz": -120,
     "elapsed": 733,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        return out2\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   look_ahead_mask, padding_mask)\n",
    "            attention_weights[f'decoder_layer{i + 1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i + 1}_block2'] = block2\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmSemJjjpNfH"
   },
   "source": [
    "# TRANSFORMER TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QCMw34fepNHC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942656630,
     "user_tz": -120,
     "elapsed": 740,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='gelu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuNecFH6o1nU"
   },
   "source": [
    "# TRANSFORMER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7UwyGFL0otlj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942659374,
     "user_tz": -120,
     "elapsed": 847,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        return final_output, attention_weights"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk3GO3wh8e16"
   },
   "source": [
    "# ENCODE TOKENIZE \\& PERSONAL TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VZGkOv_U8diI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942673268,
     "user_tz": -120,
     "elapsed": 789,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    }
   },
   "source": [
    "def encode_dataset(X, y):\n",
    "    \"\"\"\n",
    "        Creates integer encoded version of the dataset.\n",
    "    \"\"\"\n",
    "    encoded_X = TwoWay()\n",
    "    encoded_set = []\n",
    "    for row in X:\n",
    "        tmp_row = re.sub(r'<start>|<end>|<syl>', r'', row)\n",
    "        [[encoded_set.append(c) for c in w] for w in tmp_row.split('<s>')]\n",
    "    encoded_set += ['<start>', '<end>', '<s>', '<t_init>', '<t_end>']\n",
    "    encoded_set = set(encoded_set)\n",
    "    [encoded_X.add(i + 1, w) for i, w in enumerate(encoded_set)]\n",
    "    with open('resources/encoded_X.pickle', 'wb') as handle:\n",
    "        pickle.dump(encoded_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    encoded_y = TwoWay()\n",
    "    encoded_set = []\n",
    "    for row in y:\n",
    "        tmp_row = re.sub(r'<syl>', r'<s>', row)\n",
    "        tmp_row = re.sub(r'<start>|<end>|<c>', r'', tmp_row)\n",
    "        [encoded_set.append(w) for w in tmp_row.split('<s>')]\n",
    "    encoded_set += ['<syl>', '<s>', '<start>', '<end>', '<t_init>', '<t_end>', '<c>']\n",
    "    encoded_set = set(encoded_set)\n",
    "    encoded_set.remove(\"\")\n",
    "    [encoded_y.add(i + 1, w) for i, w in enumerate(encoded_set)]\n",
    "    with open('resources/encoded_y.pickle', 'wb') as handle:\n",
    "        pickle.dump(encoded_y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(\"Data saved successfully!\")\n",
    "\n",
    "\n",
    "def tokenize(two_way, line, X):\n",
    "    spaced_line = re.sub(r'<', r' <', line)\n",
    "    spaced_line = re.sub(r'>', r'> ', spaced_line)\n",
    "    spaced_line = re.sub(r'^ | $', r'', spaced_line)\n",
    "    spaced_line = re.sub(r'[ ]+', r' ', spaced_line)\n",
    "    spaced_line = spaced_line.split(' ')\n",
    "    while True:\n",
    "        try:\n",
    "            spaced_line.remove('')\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "    if X: \n",
    "        tok_X = []\n",
    "        for w in spaced_line:\n",
    "            if w in ['<start>', '<end>', '<s>', '<t_init>', '<t_end>', '<c>']:\n",
    "                tok_X.append(two_way.get(w))\n",
    "            else:\n",
    "                [tok_X.append(two_way.get(c)) for c in w]\n",
    "        return tok_X\n",
    "    else:\n",
    "        return [two_way.get(e) for e in spaced_line]\n",
    "\n",
    "\n",
    "def detokenize(two_way, line):\n",
    "    sentence = [two_way.get(e.numpy()) for e in line[0]]\n",
    "    return ''.join(sentence)\n",
    "\n",
    "\n",
    "def detokenize_(two_way, line):\n",
    "    sentence = [two_way.get(e) for e in line]\n",
    "    return ''.join(sentence)\n",
    "\n",
    "\n",
    "def make_human_understandable(sentence, keep_syl=True):\n",
    "    sentence = re.sub(r'<start>|<t_init>|<t_end>|<end>', r'', sentence)\n",
    "    if keep_syl:\n",
    "        sentence = re.sub(r'<syl>', r'|', sentence)\n",
    "    else:\n",
    "        sentence = re.sub(r'<syl>', r'', sentence)\n",
    "    sentence = re.sub(r'<s>', r' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def tokenize_pairs(X, y):\n",
    "    sliding_window = 3\n",
    "    X_tok = []\n",
    "    y_tok = []\n",
    "    for i in range(len(X)):\n",
    "        next_to_check = ''\n",
    "        for s in X[i:i + sliding_window + 3]:\n",
    "            next_to_check += s\n",
    "        if not re.search(r'<canto>', next_to_check):\n",
    "            terz = [tokenize(two_way_X, '<t_init>', X=True)[0]]\n",
    "            terz_y = [tokenize(two_way_y, '<t_init>', X=False)[0]]\n",
    "            for k in range(sliding_window):\n",
    "                if (k % 3 == 0) and (k > 0):\n",
    "                    terz += tokenize(two_way_X, '<t_end>', X=True)\n",
    "                    terz += tokenize(two_way_X, '<t_init>',X=True)\n",
    "                terz += (tokenize(two_way_X, X[i + k], X=True))\n",
    "\n",
    "            terz += tokenize(two_way_X, '<t_end>', X=True)\n",
    "            for j in range(1):\n",
    "                terz_y += (tokenize(two_way_y, y[i + j + sliding_window], X=False))\n",
    "            terz_y += tokenize(two_way_y, '<t_end>', X=False)\n",
    "            X_tok.append(terz)\n",
    "            y_tok.append(terz_y)\n",
    "\n",
    "    return X_tok, y_tok\n",
    "\n",
    "\n",
    "def make_batches(X_y_tok, batch_size):\n",
    "    batches = []\n",
    "    X_tok, y_tok = X_y_tok\n",
    "    for i in range(0, len(X_tok), batch_size):\n",
    "        if (batch_size + i) < len(X_tok):\n",
    "            batches.append((tf.cast(tf.ragged.constant(X_tok[i:i + batch_size]), tf.int64).to_tensor(),\n",
    "                            (tf.cast(tf.ragged.constant(y_tok[i:i + batch_size]), tf.int64).to_tensor())))\n",
    "        else:\n",
    "            break\n",
    "        # TODO: use the whole dataset\n",
    "    return batches"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUWxR546pUSP"
   },
   "source": [
    "# TRANSFORMER TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wsly3FnGuAcW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942681461,
     "user_tz": -120,
     "elapsed": 802,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    },
    "outputId": "e9f3cd48-9a52-46f0-fc23-efb209ac12ef"
   },
   "source": [
    "!ls "
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_6x_3y_200ep   README.md  training_data_6x_3y_200ep\r\n",
      "divine_transformer.ipynb  resources\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzS2YHQtpAqa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619942695501,
     "user_tz": -120,
     "elapsed": 9995,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    },
    "outputId": "aee998c1-4847-42c9-fbeb-9011591a7816"
   },
   "source": [
    "class TwoWay:\n",
    "    def __init__(self):\n",
    "        self.d = {}\n",
    "\n",
    "    def add(self, k, v):\n",
    "        self.d[k] = v\n",
    "        self.d[v] = k\n",
    "\n",
    "    def remove(self, k):\n",
    "        self.d.pop(self.d.pop(k))\n",
    "\n",
    "    def get(self, k):\n",
    "        return self.d[k]\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "\n",
    "# INITIALIZERS\n",
    "\n",
    "X = np.loadtxt(\"resources/X.csv\", dtype=str, delimiter=',', encoding='utf-8')\n",
    "y = np.loadtxt(\"resources/y.csv\", dtype=str, delimiter=',', encoding='utf-8')\n",
    "X_val = np.loadtxt(\"resources/X_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n",
    "y_val = np.loadtxt(\"resources/y_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n",
    "X_test = np.loadtxt(\"resources/X_test.csv\", dtype=str, delimiter=',', encoding='utf-8')\n",
    "\n",
    "# !!!!!!!!!!!!!!!\n",
    "# encode_dataset(np.hstack((X, X_val)), np.hstack((y, y_val)))\n",
    "\n",
    "with open('resources/encoded_X.pickle', 'rb') as f:\n",
    "    two_way_X = pickle.load(f)\n",
    "with open('resources/encoded_y.pickle', 'rb') as f:\n",
    "    two_way_y = pickle.load(f)\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "val_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "'''\n",
    "ORIGINALS\n",
    "\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "'''\n",
    "\n",
    "EPOCHS = 20\n",
    "num_layers = 4\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 16\n",
    "dropout_rate = 0.1\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_accuracy')\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=len(two_way_X.d),\n",
    "    target_vocab_size=len(two_way_y.d),\n",
    "    pe_input=500,\n",
    "    pe_target=500,\n",
    "    rate=dropout_rate)\n",
    "\n",
    "checkpoint_path = \"checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')\n",
    "\n",
    "\n",
    "def get_encoder_emb(two_way_X):\n",
    "    weights = transformer.tokenizer.embedding.get_weights()[0]\n",
    "    vocab = two_way_X\n",
    "\n",
    "    out_v = io.open('training_data/vectors_enc.tsv', 'w', encoding='utf-8')\n",
    "    out_m = io.open('training_data/metadata_enc.tsv', 'w', encoding='utf-8')\n",
    "    for index in range(len(vocab.d) // 2):\n",
    "        if index == 0:\n",
    "            continue  # skip 0, it's padding.\n",
    "        vec = weights[index]\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "        out_m.write(vocab.get(index) + \"\\n\")\n",
    "    out_v.close()\n",
    "    out_m.close()\n",
    "\n",
    "def get_decoder_emb(two_way_y):\n",
    "    weights = transformer.decoder.embedding.get_weights()[0]\n",
    "    vocab = two_way_y\n",
    "\n",
    "    out_v = io.open('training_data/vectors_dec.tsv', 'w', encoding='utf-8')\n",
    "    out_m = io.open('training_data/metadata_dec.tsv', 'w', encoding='utf-8')\n",
    "    for index in range(len(vocab.d) // 2):\n",
    "        if index == 0:\n",
    "            continue  # skip 0, it's padding.\n",
    "        vec = weights[index]\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "        out_m.write(vocab.get(index) + \"\\n\")\n",
    "    out_v.close()\n",
    "    out_m.close()\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def fit(train_batches, val_batches):\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        val_loss.reset_states()\n",
    "        val_accuracy.reset_states()\n",
    "\n",
    "        for (batch, (inp, tar)) in enumerate(train_batches):\n",
    "            train_step(inp, tar)\n",
    "            inp_val, tar_val = val_batches[batch % len(val_batches)]\n",
    "            validation_step(inp_val, tar_val)\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print(\n",
    "                    f'Epoch {epoch + 1} Batch {batch}'\n",
    "                    f' - Loss {train_loss.result():.4f}'\n",
    "                    f' - Accuracy {train_accuracy.result():.4f}'\n",
    "                    f' - Val Loss {val_loss.result():.4f}'\n",
    "                    f' - Val Accuracy {val_accuracy.result():.4f}'\n",
    "                )\n",
    "\n",
    "                train_accuracies.append(train_accuracy.result())\n",
    "                val_accuracies.append(val_accuracy.result())\n",
    "                train_losses.append(train_loss.result())\n",
    "                val_losses.append(val_loss.result())\n",
    "\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    ckpt_save_path = ckpt_manager.save()\n",
    "                    print(f'Saving checkpoint for epoch {epoch + 1} at {ckpt_save_path}')\n",
    "                    np.save('training_data/train_accuracies.npy', train_accuracies)\n",
    "                    np.save('training_data/val_accuracies.npy', val_accuracies)\n",
    "                    np.save('training_data/train_losses.npy', train_losses)\n",
    "                    np.save('training_data/val_losses.npy', val_losses)\n",
    "\n",
    "                    get_encoder_emb(two_way_X)\n",
    "                    get_decoder_emb(two_way_y)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "\n",
    "    return np.array(train_accuracies), np.array(train_losses), np.array(val_accuracies), np.array(val_losses)\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))\n",
    "\n",
    "\n",
    "@tf.function(input_signature=val_step_signature)\n",
    "def validation_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 False,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "    val_loss(loss)\n",
    "    val_accuracy(accuracy_function(tar_real, predictions))"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5uYNRK2sbmW"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "6ynLiX5NrNI9",
    "executionInfo": {
     "status": "error",
     "timestamp": 1619943999659,
     "user_tz": -120,
     "elapsed": 283654,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    },
    "outputId": "7f774803-068d-4149-e068-fa346b7efd93"
   },
   "source": [
    "print((detokenize_(two_way_X, tokenize_pairs(X, y)[0][0])))\n",
    "print((detokenize_(two_way_y, tokenize_pairs(X, y)[1][0])))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_batches = make_batches(tokenize_pairs(X, y), batch_size=BATCH_SIZE)\n",
    "val_batches = make_batches(tokenize_pairs(X_val, y_val), batch_size=BATCH_SIZE)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<t_init>nel<s>mezzo<s>del<s>cammin<s>di<s>nostra<s>vita<s><end>mi<s>ritrovai<s>per<s>una<s>selva<s>oscura<s><end>ché<s>la<s>diritta<s>via<s>era<s>smarrita<s><end><t_end>\n",
      "<t_init><syl>ahi<s><syl>quan<syl>to<s>a<s><syl>dir<c><s><syl>qual<s><syl>e<syl>ra<s>è<s><syl>co<syl>sa<s><syl>du<syl>ra<s><end><t_end>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    <ipython-input-11-d55f508a065e>:201 train_step  *\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    <ipython-input-7-3974dd8b7a1c>:45 create_masks  *\n        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    <ipython-input-7-3974dd8b7a1c>:32 create_look_ahead_mask  *\n        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:3212 ones\n        output = _constant_if_small(one, shape, dtype, name)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/cris/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/cris/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (strided_slice_4:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-5a41f88bf110>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mtrain_accuracies\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_accuracies\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_losses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_batches\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlength\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-d55f508a065e>\u001B[0m in \u001B[0;36mfit\u001B[0;34m(train_batches, val_batches)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    161\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 162\u001B[0;31m             \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    163\u001B[0m             \u001B[0minp_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mval_batches\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbatch\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m             \u001B[0mvalidation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    922\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    923\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 924\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    925\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    926\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3020\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[0;32m-> 3022\u001B[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[1;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3442\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3443\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3444\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3445\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3446\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3277\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3278\u001B[0m     graph_function = ConcreteFunction(\n\u001B[0;32m-> 3279\u001B[0;31m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[1;32m   3280\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3281\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    997\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    998\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 999\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1000\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1001\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcompile_with_xla\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 672\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    673\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    674\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    984\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 986\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    987\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: in user code:\n\n    <ipython-input-11-d55f508a065e>:201 train_step  *\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    <ipython-input-7-3974dd8b7a1c>:45 create_masks  *\n        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    <ipython-input-7-3974dd8b7a1c>:32 create_look_ahead_mask  *\n        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:3212 ones\n        output = _constant_if_small(one, shape, dtype, name)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/cris/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/cris/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/cris/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (strided_slice_4:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "#Saves pkl with new words not in X\n",
    "'''\n",
    "with open('resources/encoded_X.pickle', 'wb') as handle:\n",
    "    pickle.dump(two_way_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('resources/encoded_y.pickle', 'wb') as handle:\n",
    "    pickle.dump(two_way_y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''\n",
    "\n",
    "\n",
    "train_accuracies, train_losses, val_accuracies, val_losses = fit(train_batches, val_batches)\n",
    "\n",
    "def generator(length):\n",
    "    array_input = list(X_test[0:6])\n",
    "    last_input_array = []\n",
    "    for i in range(length):\n",
    "        if last_input_array:\n",
    "            [array_input.pop(0) for _ in range(3)]\n",
    "            for e in last_input_array:\n",
    "                array_input.append(re.sub(r'<syl>', '', e))\n",
    "        # from array to text\n",
    "        text_input = '<t_init>'\n",
    "        for k, s in enumerate(array_input):\n",
    "            if (k % 3 == 0) and (k > 0):\n",
    "                text_input += '<t_end>'\n",
    "                text_input += '<t_init>'\n",
    "            text_input += s\n",
    "        text_input += '<t_end>'\n",
    "        # end textification\n",
    "        # last_input, _ = evaluate.evaluate(text_input, two_way_X, two_way_y, max_length=5000)\n",
    "        text_input = re.sub(r'<c>', r'', text_input)\n",
    "        last_input = beam_search(text_input, two_way_X, two_way_y, max_length=5000)\n",
    "\n",
    "        ###\n",
    "        last_input = re.sub(r'<t_init>|<t_end>', r'', last_input)\n",
    "        last_input = re.sub(r'<end>', r'<end>+', last_input)\n",
    "        last_input_array = last_input.split('+')\n",
    "        for l in last_input_array:\n",
    "            print(make_human_understandable(l, True))\n",
    "        print()\n",
    "\n",
    "\n",
    "generator(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "sx1SxSpCynEj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1619944233539,
     "user_tz": -120,
     "elapsed": 1578,
     "user": {
      "displayName": "Serban Cristian Tudosie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64",
      "userId": "15345692188992114213"
     }
    },
    "outputId": "1051d2fc-1f1e-46c3-caab-59f45f0fdfb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
    "    translated_tokens = translated_tokens[1:]\n",
    "    ax = plt.gca()\n",
    "    ax.matshow(attention)\n",
    "    ax.set_xticks(range(len(in_tokens)))\n",
    "    ax.set_yticks(range(len(translated_tokens)))\n",
    "    labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "\n",
    "def print_acc_loss():\n",
    "    train_accuracies = np.load('training_data/train_accuracies.npy')\n",
    "    val_accuracies = np.load('training_data/val_accuracies.npy')\n",
    "    train_losses = np.load('training_data/train_losses.npy')\n",
    "    val_losses = np.load('training_data/val_losses.npy')\n",
    "\n",
    "    plt.title(\"Accuracies\")\n",
    "    plt.plot(range(0, 25 * len(train_accuracies), 25), train_accuracies)\n",
    "    plt.plot(range(0, 25 * len(train_accuracies), 25), val_accuracies)\n",
    "    plt.xlabel(\"Num batch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend([\"train_acc\", \"val_acc\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_data/Acc_3x_1y_20ep_chars.png')\n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(range(0, 25 * len(train_accuracies), 25), train_losses)\n",
    "    plt.plot(range(0, 25 * len(train_accuracies), 25), val_losses)\n",
    "    plt.xlabel(\"Num batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"train_loss\", \"val_loss\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_data/Loss_3x_1y_20ep_chars.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print_acc_loss()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}