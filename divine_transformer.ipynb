{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"divine_transformer_big.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IktUvj6AndiG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619972145353,"user_tz":-120,"elapsed":523,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"6b8e831f-b52d-45a8-8377-4fd5f48d66b1"},"source":["import io\n","import pickle\n","import time\n","import numpy as np\n","import random\n","import sys\n","import time\n","import copy\n","import re\n","import tensorflow as tf\n","\n","'''\n","ORIGINALS\n","\n","num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.1\n","'''\n","\n","EPOCHS = 20\n","num_layers = 4\n","d_model = 256\n","dff = 1024\n","num_heads = 8\n","dropout_rate = 0.1\n","BATCH_SIZE = 128\n","PRINT_EACH_BATCHES = 100\n","\n","N_BEAM = 2\n","K = 20\n","TEMP = 1.1\n","\n","sliding_window_X = 9\n","sliding_window_y = 3\n","SAVING_STEP = 5\n","\n","##########################\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":141,"outputs":[{"output_type":"stream","text":["Sun May  2 16:15:55 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    34W / 250W |  15393MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNtKlcYAqGYw","executionInfo":{"status":"ok","timestamp":1619972148266,"user_tz":-120,"elapsed":3426,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"a2710b89-5341-457d-8350-df2c2a9b1302"},"source":["\n","# UNCOMMENT IF YOU ARE ON COLAB\n","\n","!pip install levenshtein\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/transformer/'\n","\n","# REMEMBER TO SET THE ROOT PATH WITH A REGEX IN ALL THE NOTEBOOK\n","# gdrive/MyDrive/transformer/\n","\n","from Levenshtein import distance as levenshtein_distance"],"execution_count":142,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from levenshtein) (56.0.0)\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lwsdLDJMn0ar"},"source":["## ATTENTION"]},{"cell_type":"code","metadata":{"id":"_qm-mmfSnv-y","executionInfo":{"status":"ok","timestamp":1619972148267,"user_tz":-120,"elapsed":3415,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","    return output, attention_weights\n","\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        assert d_model % self.num_heads == 0\n","        self.depth = d_model // self.num_heads\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention,\n","                                        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","        concat_attention = tf.reshape(scaled_attention,\n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        return output, attention_weights\n"],"execution_count":143,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0OFoYvHn5Ei"},"source":["## EVALUATE"]},{"cell_type":"code","metadata":{"id":"TJwuxgfVohBG","executionInfo":{"status":"ok","timestamp":1619972148267,"user_tz":-120,"elapsed":3408,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def sampling(k, predictions, prev_pred, space, syl, start):\n","    def generation(temp):\n","        top_k_id, top_k_prob = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n","                               (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n","        top_k_prob = top_k_prob ** temp\n","        prob_sum = sum(top_k_prob)\n","        r = random.random() * prob_sum\n","        j = 0\n","        while True:\n","            if r - top_k_prob[j] <= 0:\n","                return tf.cast(tf.convert_to_tensor([[top_k_id[j]]]), tf.int64)\n","            r -= top_k_prob[j]\n","            j += 1\n","\n","    if len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl:\n","        prediction_id = generation(3)\n","    elif len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl:\n","        prediction_id = generation(-3)\n","    else:\n","        prediction_id = tf.argmax(predictions, axis=-1)\n","    return prediction_id\n","\n","\n","def evaluate(sentence, two_way_X, two_way_y, max_length=1000):\n","    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence)]), tf.int64)\n","\n","    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n","    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n","    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n","    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n","    output = tf.convert_to_tensor([t_init])\n","    output = tf.expand_dims(output, 0)\n","    output = tf.cast(output, tf.int64)\n","\n","    prev_pred = [t_init]\n","\n","    for i in range(max_length):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","        # predictions.shape == (batch_size, seq_len, vocab_size)\n","        predictions, attention_weights = transformer(encoder_input,\n","                                                     output,\n","                                                     False,\n","                                                     enc_padding_mask,\n","                                                     combined_mask,\n","                                                     dec_padding_mask)\n","        # select the last word from the seq_len dimension\n","        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","\n","        predicted_id = sampling(10, predictions, prev_pred, space, syl, start)\n","\n","        prev_pred.append(predicted_id)\n","        output = tf.concat([output, predicted_id], axis=-1)\n","        # return the result if the predicted_id is equal to the end token\n","        if predicted_id == t_end:\n","            break\n","    # output.shape (1, tokens)\n","    text = detokenize(two_way_y, output)\n","    return text, attention_weights\n","\n","\n","def evaluate_test(X_test, y_test, two_way_X, two_way_y):\n","    print(len(X_test))\n","    distances = []\n","    for query_sent, true_sent in zip(X_test[30:50], y_test[30:50]):\n","        pred_text, attention_w = evaluate(query_sent, two_way_X, two_way_y)\n","        pred_text = make_human_understandable(pred_text)\n","        true_sent = make_human_understandable(true_sent)\n","        print(f\"pred: {pred_text}\\norig: {true_sent}\")\n","        lev = levenshtein_distance(pred_text, true_sent)\n","        lower = abs(len(pred_text) - len(true_sent))\n","        upper = max(len(pred_text), len(true_sent))\n","        distances.append((lev - lower) / (upper - lower))\n","    print(1 - np.mean(distances))"],"execution_count":144,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfdLb_Y0HkIs"},"source":["# BEAM SEARCH"]},{"cell_type":"code","metadata":{"id":"HB-Uhb6XHjUU","executionInfo":{"status":"ok","timestamp":1619972148268,"user_tz":-120,"elapsed":3402,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def sampling_flows(flows_array):\n","    all_flows = copy.deepcopy(flows_array)\n","    drawn_flows = []\n","    for _ in range(N_BEAM):\n","        top_k_prob = [f.prob for f in all_flows]\n","        top_k_prob = np.array([e if e > 0 else 0.05 for e in top_k_prob])\n","        top_k_prob = top_k_prob ** TEMP\n","        prob_sum = sum(top_k_prob)\n","        r = random.random() * prob_sum\n","        j = 0\n","        while True:\n","            if r - top_k_prob[j] <= 0:\n","                drawn_flows.append(all_flows[j])\n","                all_flows.pop(j)\n","                break\n","            r -= top_k_prob[j]\n","            j += 1\n","    return drawn_flows\n","\n","\n","def next_predictions(encoder_input, output, k, argmax):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n","    predictions, attention_weights = transformer(encoder_input,\n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n","    if not argmax:\n","        top_k_id_, top_k_prob_ = (tf.nn.top_k(predictions, k=k)[1]).numpy()[0][0], \\\n","                                 (tf.nn.top_k(predictions, k=k)[0]).numpy()[0][0]\n","        return top_k_id_, top_k_prob_\n","    else:\n","        return tf.argmax(predictions, axis=-1)\n","\n","\n","class Flow:\n","    def __init__(self, init, prob):\n","        self.output = init\n","        self.prob = prob\n","\n","\n","def beam_search(sentence, two_way_X, two_way_y, max_length=1000):\n","    encoder_input = tf.cast(tf.convert_to_tensor([tokenize(two_way_X, sentence, X=True)]), tf.int64)\n","    t_init, t_end = two_way_y.get('<t_init>'), two_way_y.get('<t_end>')\n","    start, end = two_way_y.get('<start>'), two_way_y.get('<end>')\n","    space = tf.cast(tf.convert_to_tensor([two_way_y.get('<s>')]), tf.int64)\n","    syl = tf.cast(tf.convert_to_tensor([two_way_y.get('<syl>')]), tf.int64)\n","    output = tf.convert_to_tensor([t_init])\n","    output = tf.expand_dims(output, 0)\n","    output = tf.cast(output, tf.int64)\n","\n","    flows_array = [Flow(output, 1)]\n","    best_flows = []\n","    for u in range(max_length):\n","        if False and u % 11 == 0:\n","            print(\"Generazione sillaba: \" + str(u))\n","        new_flow_array = []\n","        for e in flows_array:\n","            prev_pred = e.output.numpy().flatten()\n","            if (len(prev_pred) > 1 and prev_pred[-2] == space and prev_pred[-1] == syl) or \\\n","                    (len(prev_pred) > 1 and prev_pred[-2] == start and prev_pred[-1] == syl):\n","                top_k_id, top_k_prob = next_predictions(encoder_input, e.output, k=K, argmax=False)\n","                for i in range(len(top_k_id)):\n","                    new_out = tf.concat(\n","                        [(copy.deepcopy(e)).output, tf.cast(tf.convert_to_tensor([[top_k_id[i]]]), tf.int64)], axis=-1)\n","                    new_flow_array.append(Flow(new_out, top_k_prob[i] * e.prob))\n","            else:\n","                new_out = tf.concat(\n","                    [(copy.deepcopy(e)).output, next_predictions(encoder_input, e.output, k=K, argmax=True)], axis=-1)\n","                new_flow_array.append(Flow(new_out, e.prob))\n","\n","        flows_array = new_flow_array\n","        # flows_array = sorted(flows_array, key=lambda f: f.prob, reverse=True)[:N_BEAM]\n","        if len(flows_array) > N_BEAM:\n","            flows_array = sampling_flows(flows_array)\n","\n","        to_pop = []\n","        for j, flow in enumerate(flows_array):\n","            if flow.output.numpy().flatten()[-1] == t_end:\n","                best_flows.append(flow)\n","                to_pop.append(flow)\n","        [flows_array.remove(p) for p in to_pop]\n","        if len(best_flows) == N_BEAM:\n","            result = (max(best_flows, key=lambda f: f.prob)).output\n","            text = detokenize(two_way_y, result)\n","            return text\n"],"execution_count":145,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkJy3R0DrjLz"},"source":["# ENCODER DECODER"]},{"cell_type":"code","metadata":{"id":"rw8o-6mbrdAu","executionInfo":{"status":"ok","timestamp":1619972148598,"user_tz":-120,"elapsed":3727,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","        return out2\n","\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        # enc_output.shape == (batch_size, input_seq_len, d_model)\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","        attn2, attn_weights_block2 = self.mha2(\n","            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","        return out3, attn_weights_block1, attn_weights_block2\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                 maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                self.d_model)\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n","                           for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","        # adding embedding and position encoding.\n","        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","        return x  # (batch_size, input_seq_len, d_model)\n","\n","\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","                 maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n","                           for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                                   look_ahead_mask, padding_mask)\n","            attention_weights[f'decoder_layer{i + 1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i + 1}_block2'] = block2\n","        # x.shape == (batch_size, target_seq_len, d_model)\n","        return x, attention_weights\n"],"execution_count":146,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmSemJjjpNfH"},"source":["# TRANSFORMER TOOLS"]},{"cell_type":"code","metadata":{"id":"QCMw34fepNHC","executionInfo":{"status":"ok","timestamp":1619972148598,"user_tz":-120,"elapsed":3721,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis, :],\n","                            d_model)\n","\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='gelu'),  # (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # add extra dimensions to add the padding\n","    # to the attention logits.\n","    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n","\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask  # (seq_len, seq_len)\n","\n","\n","def create_masks(inp, tar):\n","    # Encoder padding mask\n","    enc_padding_mask = create_padding_mask(inp)\n","    # Used in the 2nd attention block in the decoder.\n","    # This padding mask is used to mask the encoder outputs.\n","    dec_padding_mask = create_padding_mask(inp)\n","    # Used in the 1st attention block in the decoder.\n","    # It is used to pad and mask future tokens in the input received by\n","    # the decoder.\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, combined_mask, dec_padding_mask\n"],"execution_count":147,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xuNecFH6o1nU"},"source":["# TRANSFORMER CLASS"]},{"cell_type":"code","metadata":{"id":"7UwyGFL0otlj","executionInfo":{"status":"ok","timestamp":1619972148599,"user_tz":-120,"elapsed":3715,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                 target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","        self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n","                                 input_vocab_size, pe_input, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n","                               target_vocab_size, pe_target, rate)\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","        dec_output, attention_weights = self.decoder(\n","            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","        return final_output, attention_weights"],"execution_count":148,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uk3GO3wh8e16"},"source":["# ENCODE TOKENIZE \\& PERSONAL TOOLS"]},{"cell_type":"code","metadata":{"id":"VZGkOv_U8diI","executionInfo":{"status":"ok","timestamp":1619972148816,"user_tz":-120,"elapsed":3927,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["def encode_dataset(X, y):\n","    \"\"\"\n","        Creates integer encoded version of the dataset.\n","    \"\"\"\n","    encoded_X = TwoWay()\n","    encoded_set = []\n","    for row in X:\n","        tmp_row = re.sub(r'<start>|<end>|<syl>', r'', row)\n","        [[encoded_set.append(c) for c in w] for w in tmp_row.split('<s>')]\n","    encoded_set += ['<start>', '<end>', '<s>', '<t_init>', '<t_end>']\n","    encoded_set = set(encoded_set)\n","    [encoded_X.add(i + 1, w) for i, w in enumerate(encoded_set)]\n","    with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'wb') as handle:\n","        pickle.dump(encoded_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    encoded_y = TwoWay()\n","    encoded_set = []\n","    for row in y:\n","        tmp_row = re.sub(r'<syl>', r'<s>', row)\n","        tmp_row = re.sub(r'<start>|<end>|<c>', r'', tmp_row)\n","        [encoded_set.append(w) for w in tmp_row.split('<s>')]\n","    encoded_set += ['<syl>', '<s>', '<start>', '<end>', '<t_init>', '<t_end>', '<c>']\n","    encoded_set = set(encoded_set)\n","    encoded_set.remove(\"\")\n","    [encoded_y.add(i + 1, w) for i, w in enumerate(encoded_set)]\n","    with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'wb') as handle:\n","        pickle.dump(encoded_y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    print(\"Data saved successfully!\")\n","\n","\n","def tokenize(two_way, line, X):\n","    spaced_line = re.sub(r'<', r' <', line)\n","    spaced_line = re.sub(r'>', r'> ', spaced_line)\n","    spaced_line = re.sub(r'^ | $', r'', spaced_line)\n","    spaced_line = re.sub(r'[ ]+', r' ', spaced_line)\n","    spaced_line = spaced_line.split(' ')\n","    while True:\n","        try:\n","            spaced_line.remove('')\n","        except ValueError:\n","            break\n","\n","    if X: \n","        tok_X = []\n","        for w in spaced_line:\n","            if w in ['<start>', '<end>', '<s>', '<t_init>', '<t_end>', '<c>']:\n","                tok_X.append(two_way.get(w))\n","            else:\n","                [tok_X.append(two_way.get(c)) for c in w]\n","        return tok_X\n","    else:\n","        return [two_way.get(e) for e in spaced_line]\n","\n","\n","def detokenize(two_way, line):\n","    sentence = [two_way.get(e.numpy()) for e in line[0]]\n","    return ''.join(sentence)\n","\n","\n","def detokenize_(two_way, line):\n","    sentence = [two_way.get(e) for e in line]\n","    return ''.join(sentence)\n","\n","\n","def make_human_understandable(sentence, keep_syl=True):\n","    sentence = re.sub(r'<start>|<t_init>|<t_end>|<end>', r'', sentence)\n","    if keep_syl:\n","        sentence = re.sub(r'<syl>', r'|', sentence)\n","    else:\n","        sentence = re.sub(r'<syl>', r'', sentence)\n","    sentence = re.sub(r'<s>', r' ', sentence)\n","    return sentence\n","\n","\n","def tokenize_pairs(X, y):\n","\n","    X_tok = []\n","    y_tok = []\n","    for i in range(len(X)):\n","        next_to_check = ''\n","        for s in X[i:i + sliding_window_X + sliding_window_y]:\n","            next_to_check += s\n","        if not re.search(r'<canto>', next_to_check):\n","            terz = [tokenize(two_way_X, '<t_init>', X=True)[0]]\n","            terz_y = [tokenize(two_way_y, '<t_init>', X=False)[0]]\n","            for k in range(sliding_window_X):\n","                if (k % 3 == 0) and (k > 0):\n","                    terz += tokenize(two_way_X, '<t_end>', X=True)\n","                    terz += tokenize(two_way_X, '<t_init>',X=True)\n","                terz += (tokenize(two_way_X, X[i + k], X=True))\n","\n","            terz += tokenize(two_way_X, '<t_end>', X=True)\n","            for j in range(sliding_window_y):\n","                terz_y += (tokenize(two_way_y, y[i + j + sliding_window_X], X=False))\n","            terz_y += tokenize(two_way_y, '<t_end>', X=False)\n","            X_tok.append(terz)\n","            y_tok.append(terz_y)\n","\n","    return X_tok, y_tok\n","\n","\n","def make_batches(X_y_tok, batch_size):\n","    batches = []\n","    X_tok, y_tok = X_y_tok\n","    for i in range(0, len(X_tok), batch_size):\n","        if (batch_size + i) < len(X_tok):\n","            batches.append((tf.cast(tf.ragged.constant(X_tok[i:i + batch_size]), tf.int64).to_tensor(),\n","                            (tf.cast(tf.ragged.constant(y_tok[i:i + batch_size]), tf.int64).to_tensor())))\n","        else:\n","            break\n","        # TODO: use the whole dataset\n","    return batches"],"execution_count":149,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QUWxR546pUSP"},"source":["# TRANSFORMER TRAINING"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wsly3FnGuAcW","executionInfo":{"status":"ok","timestamp":1619972148816,"user_tz":-120,"elapsed":3922,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"298aa97a-722c-4396-a0f1-e13edca888d7"},"source":["!ls "],"execution_count":150,"outputs":[{"output_type":"stream","text":["checkpoints  gdrive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nzS2YHQtpAqa","executionInfo":{"status":"ok","timestamp":1619972149476,"user_tz":-120,"elapsed":4572,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["class TwoWay:\n","    def __init__(self):\n","        self.d = {}\n","\n","    def add(self, k, v):\n","        self.d[k] = v\n","        self.d[v] = k\n","\n","    def remove(self, k):\n","        self.d.pop(self.d.pop(k))\n","\n","    def get(self, k):\n","        return self.d[k]\n","\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","\n","\n","# INITIALIZERS\n","\n","X = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","y = np.loadtxt(\"gdrive/MyDrive/transformer/resources/y.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","X_val = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","y_val = np.loadtxt(\"gdrive/MyDrive/transformer/resources/y_val.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","X_test = np.loadtxt(\"gdrive/MyDrive/transformer/resources/X_test.csv\", dtype=str, delimiter=',', encoding='utf-8')\n","\n","# !!!!!!!!!!!!!!!\n","# encode_dataset(np.hstack((X, X_val)), np.hstack((y, y_val)))\n","\n","with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'rb') as f:\n","    two_way_X = pickle.load(f)\n","with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'rb') as f:\n","    two_way_y = pickle.load(f)\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","val_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","\n","learning_rate = CustomSchedule(d_model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n","val_loss = tf.keras.metrics.Mean(name='val_accuracy')\n","\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=len(two_way_X.d),\n","    target_vocab_size=len(two_way_y.d),\n","    pe_input=500,\n","    pe_target=500,\n","    rate=dropout_rate)\n","\n","checkpoint_path = \"gdrive/MyDrive/transformer/checkpoints/train\"\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print('Latest checkpoint restored!!')\n","\n","\n","def get_encoder_emb(two_way_X):\n","    weights = transformer.tokenizer.embedding.get_weights()[0]\n","    vocab = two_way_X\n","\n","    out_v = io.open('gdrive/MyDrive/transformer/training_data/vectors_enc.tsv', 'w', encoding='utf-8')\n","    out_m = io.open('gdrive/MyDrive/transformer/training_data/metadata_enc.tsv', 'w', encoding='utf-8')\n","    for index in range(len(vocab.d) // 2):\n","        if index == 0:\n","            continue  # skip 0, it's padding.\n","        vec = weights[index]\n","        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","        out_m.write(vocab.get(index) + \"\\n\")\n","    out_v.close()\n","    out_m.close()\n","\n","def get_decoder_emb(two_way_y):\n","    weights = transformer.decoder.embedding.get_weights()[0]\n","    vocab = two_way_y\n","\n","    out_v = io.open('gdrive/MyDrive/transformer/training_data/vectors_dec.tsv', 'w', encoding='utf-8')\n","    out_m = io.open('gdrive/MyDrive/transformer/training_data/metadata_dec.tsv', 'w', encoding='utf-8')\n","    for index in range(len(vocab.d) // 2):\n","        if index == 0:\n","            continue  # skip 0, it's padding.\n","        vec = weights[index]\n","        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","        out_m.write(vocab.get(index) + \"\\n\")\n","    out_v.close()\n","    out_m.close()\n","\n","def accuracy_function(real, pred):\n","    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n","\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n","\n","\n","def fit(train_batches, val_batches):\n","    train_accuracies = []\n","    val_accuracies = []\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(EPOCHS):\n","        start = time.time()\n","        train_loss.reset_states()\n","        train_accuracy.reset_states()\n","        val_loss.reset_states()\n","        val_accuracy.reset_states()\n","\n","        for (batch, (inp, tar)) in enumerate(train_batches):\n","            train_step(inp, tar)\n","            inp_val, tar_val = val_batches[batch % len(val_batches)]\n","            validation_step(inp_val, tar_val)\n","\n","            if batch % PRINT_EACH_BATCHES == 0:\n","                print(\n","                    f'Epoch {epoch + 1} Batch {batch}'\n","                    f' - Loss {train_loss.result():.4f}'\n","                    f' - Accuracy {train_accuracy.result():.4f}'\n","                    f' - Val Loss {val_loss.result():.4f}'\n","                    f' - Val Accuracy {val_accuracy.result():.4f}'\n","                )\n","\n","                train_accuracies.append(train_accuracy.result())\n","                val_accuracies.append(val_accuracy.result())\n","                train_losses.append(train_loss.result())\n","                val_losses.append(val_loss.result())\n","\n","                if (epoch + 1) % SAVING_STEP == 0:\n","                    ckpt_save_path = ckpt_manager.save()\n","                    print(f'Saving checkpoint for epoch {epoch + 1} at {ckpt_save_path}')\n","                    np.save('gdrive/MyDrive/transformer/training_data/train_accuracies.npy', train_accuracies)\n","                    np.save('gdrive/MyDrive/transformer/training_data/val_accuracies.npy', val_accuracies)\n","                    np.save('gdrive/MyDrive/transformer/training_data/train_losses.npy', train_losses)\n","                    np.save('gdrive/MyDrive/transformer/training_data/val_losses.npy', val_losses)\n","\n","                    get_encoder_emb(two_way_X)\n","                    get_decoder_emb(two_way_y)\n","\n","        print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n","        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n","\n","    return np.array(train_accuracies), np.array(train_losses), np.array(val_accuracies), np.array(val_losses)\n","\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(inp, tar_inp,\n","                                     True,\n","                                     enc_padding_mask,\n","                                     combined_mask,\n","                                     dec_padding_mask)\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","    train_loss(loss)\n","    train_accuracy(accuracy_function(tar_real, predictions))\n","\n","\n","@tf.function(input_signature=val_step_signature)\n","def validation_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","    predictions, _ = transformer(inp, tar_inp,\n","                                 False,\n","                                 enc_padding_mask,\n","                                 combined_mask,\n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","    val_loss(loss)\n","    val_accuracy(accuracy_function(tar_real, predictions))"],"execution_count":151,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s5uYNRK2sbmW"},"source":["# MAIN"]},{"cell_type":"code","metadata":{"id":"6ynLiX5NrNI9","executionInfo":{"status":"ok","timestamp":1619972168591,"user_tz":-120,"elapsed":23682,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["# print((detokenize_(two_way_X, tokenize_pairs(X, y)[0][0])))\n","# print((detokenize_(two_way_y, tokenize_pairs(X, y)[1][0])))\n","\n","\n","train_batches = make_batches(tokenize_pairs(X, y), batch_size=BATCH_SIZE)\n","val_batches = make_batches(tokenize_pairs(X_val, y_val), batch_size=BATCH_SIZE)"],"execution_count":152,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":673},"id":"uTN7sagkRqNz","executionInfo":{"status":"error","timestamp":1619972601863,"user_tz":-120,"elapsed":456949,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}},"outputId":"2ef37ee7-ddff-487b-8ad2-ca29ffb3f999"},"source":["#Saves pkl with new words not in X\n","'''\n","with open('gdrive/MyDrive/transformer/resources/encoded_X.pickle', 'wb') as handle:\n","    pickle.dump(two_way_X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","with open('gdrive/MyDrive/transformer/resources/encoded_y.pickle', 'wb') as handle:\n","    pickle.dump(two_way_y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","'''\n","\n","\n","train_accuracies, train_losses, val_accuracies, val_losses = fit(train_batches, val_batches)\n","\n","def generator(length):\n","    array_input = list(X_val[0:sliding_window_X])\n","    last_input_array = []\n","    for i in range(length):\n","        if last_input_array:\n","            [array_input.pop(0) for _ in range(sliding_window_y)]\n","            for e in last_input_array:\n","                array_input.append(re.sub(r'<syl>', '', e))\n","        # from array to text\n","        text_input = '<t_init>'\n","        for k, s in enumerate(array_input):\n","            if (k % 3 == 0) and (k > 0):\n","                text_input += '<t_end>'\n","                text_input += '<t_init>'\n","            text_input += s\n","        text_input += '<t_end>'\n","        # end textification\n","        # last_input, _ = evaluate.evaluate(text_input, two_way_X, two_way_y, max_length=5000)\n","        text_input = re.sub(r'<c>', r'', text_input)\n","        last_input = beam_search(text_input, two_way_X, two_way_y, max_length=5000)\n","\n","        ###\n","        last_input = re.sub(r'<t_init>|<t_end>', r'', last_input)\n","        last_input = re.sub(r'<end>', r'<end>+', last_input)\n","        last_input_array = last_input.split('+')\n","        for l in last_input_array:\n","            print(make_human_understandable(l, True))\n","        print()\n","\n","\n","generator(10)"],"execution_count":153,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 - Loss 8.2665 - Accuracy 0.0000 - Val Loss 8.2706 - Val Accuracy 0.0000\n","Epoch 1 Loss 6.8460 Accuracy 0.2471\n","Time taken for 1 epoch: 112.47 secs\n","\n","Epoch 2 Batch 0 - Loss 5.7796 - Accuracy 0.3257 - Val Loss 5.6673 - Val Accuracy 0.3310\n","Epoch 2 Loss 5.1753 Accuracy 0.3346\n","Time taken for 1 epoch: 98.00 secs\n","\n","Epoch 3 Batch 0 - Loss 4.3599 - Accuracy 0.4222 - Val Loss 4.2625 - Val Accuracy 0.4453\n","Epoch 3 Loss 3.5597 Accuracy 0.4847\n","Time taken for 1 epoch: 98.04 secs\n","\n","Epoch 4 Batch 0 - Loss 2.9756 - Accuracy 0.5159 - Val Loss 2.9057 - Val Accuracy 0.5127\n","Epoch 4 Loss 2.6696 Accuracy 0.5289\n","Time taken for 1 epoch: 98.04 secs\n","\n","Epoch 5 Batch 0 - Loss 2.4517 - Accuracy 0.5461 - Val Loss 2.4207 - Val Accuracy 0.5472\n","Saving checkpoint for epoch 5 at gdrive/MyDrive/transformer/checkpoints/train/ckpt-1\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-153-8eca91ab8277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-151-b1c9f731c4d1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_batches, val_batches)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0minp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sx1SxSpCynEj","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"aborted","timestamp":1619972601860,"user_tz":-120,"elapsed":456938,"user":{"displayName":"Serban Cristian Tudosie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjKcHtWlRmEx5gPgHp_XElg5R9_lOdYkNWR-WiUiw=s64","userId":"15345692188992114213"}}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_attention_head(in_tokens, translated_tokens, attention):\n","    translated_tokens = translated_tokens[1:]\n","    ax = plt.gca()\n","    ax.matshow(attention)\n","    ax.set_xticks(range(len(in_tokens)))\n","    ax.set_yticks(range(len(translated_tokens)))\n","    labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n","    ax.set_xticklabels(labels, rotation=90)\n","    labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n","    ax.set_yticklabels(labels)\n","\n","\n","def print_acc_loss():\n","    train_accuracies = np.load('gdrive/MyDrive/transformer/training_data/train_accuracies.npy')\n","    val_accuracies = np.load('gdrive/MyDrive/transformer/training_data/val_accuracies.npy')\n","    train_losses = np.load('gdrive/MyDrive/transformer/training_data/train_losses.npy')\n","    val_losses = np.load('gdrive/MyDrive/transformer/training_data/val_losses.npy')\n","\n","    plt.title(\"Accuracies\")\n","    plt.plot(range(0, PRINT_EACH_BATCHES * len(train_accuracies), PRINT_EACH_BATCHES), train_accuracies)\n","    plt.plot(range(0, PRINT_EACH_BATCHES * len(train_accuracies), PRINT_EACH_BATCHES), val_accuracies)\n","    plt.xlabel(\"Num batch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend([\"trUntitled folderain_acc\", \"val_acc\"])\n","    plt.tight_layout()\n","    plt.savefig(f'gdrive/MyDrive/transformer/training_data/Acc_{sliding_window_X}x_{sliding_window_y}y_{EPOCHS}ep_chars.png')\n","    plt.show()\n","    print()\n","\n","    plt.title(\"Loss\")\n","    plt.plot(range(0, PRINT_EACH_BATCHES * len(train_accuracies), PRINT_EACH_BATCHES), train_losses)\n","    plt.plot(range(0, PRINT_EACH_BATCHES * len(train_accuracies), PRINT_EACH_BATCHES), val_losses)\n","    plt.xlabel(\"Num batch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend([\"train_loss\", \"val_loss\"])\n","    plt.tight_layout()\n","    plt.savefig(f'gdrive/MyDrive/transformer/training_data/Loss_{sliding_window_X}x_{sliding_window_y}y_{EPOCHS}ep_chars.png')\n","    plt.show()\n","\n","\n","print_acc_loss()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fa6hGuP3ZNgv"},"source":["**italicized** text"]}]}